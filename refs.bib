%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Neil Ernst at 2020-11-26 17:34:16 -0800 


%% Saved with string encoding Unicode (UTF-8) 

@article{2020arXiv201102861S,
	adsnote = {Provided by the SAO/NASA Astrophysics Data System},
	adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv201102861S},
	archiveprefix = {arXiv},
	author = {{Santos}, Adrian and {Vegas}, Sira and {Oivo}, Markku and {Juristo}, Natalia},
	date-added = {2020-11-26 17:33:12 -0800},
	date-modified = {2020-11-26 17:33:12 -0800},
	eid = {arXiv:2011.02861},
	eprint = {2011.02861},
	journal = {arXiv e-prints},
	keywords = {Computer Science - Software Engineering},
	month = nov,
	pages = {arXiv:2011.02861},
	primaryclass = {cs.SE},
	title = {{Comparing the Results of Replications in Software Engineering}},
	year = 2020}

@article{DeVito2020,
	author = {Nicholas J DeVito and Seb Bacon and Ben Goldacre},
	date-added = {2020-11-26 16:57:42 -0800},
	date-modified = {2020-11-26 16:57:42 -0800},
	doi = {10.1016/s0140-6736(19)33220-9},
	journal = {The Lancet},
	month = {feb},
	number = {10221},
	pages = {361--369},
	publisher = {Elsevier {BV}},
	title = {Compliance with legal requirement to report clinical trial results on {ClinicalTrials}.gov: a cohort study},
	volume = {395},
	year = 2020}

@url{tbl90,
	author = {Tim Berners-Lee},
	date-added = {2020-11-26 16:53:21 -0800},
	date-modified = {2020-11-26 16:54:16 -0800},
	lastchecked = {November 2020},
	title = {Information Management: A Proposal},
	url = {https://www.w3.org/History/1989/proposal.html},
	urldate = {1990}}

@article{Schimmack2020,
	author = {Ulrich Schimmack},
	date-added = {2020-11-26 16:43:37 -0800},
	date-modified = {2020-11-26 16:43:59 -0800},
	doi = {10.1037/cap0000246},
	journal = {Canadian Psychology/Psychologie canadienne},
	month = {nov},
	number = {4},
	pages = {364--376},
	publisher = {American Psychological Association ({APA})},
	title = {A meta-psychological perspective on the decade of replication failures in social psychology.},
	volume = {61},
	year = 2020}

@incollection{Mendez2020,
	author = {Daniel Mendez and Daniel Graziotin and Stefan Wagner and Heidi Seibold},
	booktitle = {Contemporary Empirical Methods in Software Engineering},
	date-added = {2020-11-26 16:07:04 -0800},
	date-modified = {2020-11-26 16:07:04 -0800},
	doi = {10.1007/978-3-030-32489-6\_17},
	pages = {477--501},
	publisher = {Springer International Publishing},
	title = {Open Science in Software Engineering},
	year = 2020}

@misc{Sayyad2005,
	author = {Sayyad Shirabad, J. and Menzies, T.J.},
	date-added = {2020-11-26 16:01:41 -0800},
	date-modified = {2020-11-26 16:01:58 -0800},
	howpublished = {School of Information Technology and Engineering, University of Ottawa, Canada},
	title = {{The {PROMISE} Repository of Software Engineering Databases.}},
	url = {http://promise.site.uottawa.ca/SERepository},
	year = {2005}}

@article{menzies2013guest,
	author = {Menzies, Tim},
	journal = {Information and Software Technology},
	number = {8},
	pages = {1477--1478},
	publisher = {Butterworth-Heinemann Newton, MA, USA},
	title = {Guest editorial for the Special Section on BEST PAPERS from the 2011 conference on Predictive Models in Software Engineering (PROMISE)},
	volume = {55},
	year = {2013}}

@misc{chambers2019s,
	author = {Chambers, Chris},
	publisher = {Nature Publishing Group},
	title = {What's next for registered reports?},
	year = {2019}}

@inproceedings{bergstra2011algorithms,
	author = {Bergstra, James S and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
	booktitle = {Advances in neural information processing systems},
	pages = {2546--2554},
	title = {Algorithms for hyper-parameter optimization},
	year = {2011}}

@inproceedings{10.1145/3368089.3409767,
author = {Hermann, Ben and Winter, Stefan and Siegmund, Janet},
title = {Community Expectations for Research Artifacts and Evaluation Processes},
year = {2020},
isbn = {9781450370431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368089.3409767},
doi = {10.1145/3368089.3409767},
abstract = {Background. Artifact evaluation has been introduced into the software engineering and programming languages research community with a pilot at ESEC/FSE 2011 and has since then enjoyed a healthy adoption throughout the conference landscape. Objective. In this qualitative study, we examine the expectations of the community toward research artifacts and their evaluation processes. Method. We conducted a survey including all members of artifact evaluation committees of major conferences in the software engineering and programming language field since the first pilot and compared the answers to expectations set by calls for artifacts and reviewing guidelines. Results. While we find that some expectations exceed the ones expressed in calls and reviewing guidelines, there is no consensus on quality thresholds for artifacts in general. We observe very specific quality expectations for specific artifact types for review and later usage, but also a lack of their communication in calls. We also find problematic inconsistencies in the terminology used to express artifact evaluation’s most important purpose – replicability. Conclusion. We derive several actionable suggestions which can help to mature artifact evaluation in the inspected community and also to aid its introduction into other communities in computer science.},
booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {469–480},
numpages = {12},
keywords = {Reproducibility, Artifact Evaluation, Study, Replicability},
location = {Virtual Event, USA},
series = {ESEC/FSE 2020}
}