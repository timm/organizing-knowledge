
\begin{table}[!t]
\caption{Artifact types from SE publications. Current artifact evaluation committees in software engineering and programming conferences typically review just the green items 19,20,21,22,23.
Also, usually, items 1,2,3,4,5,6,7,8,9 are typically  evaluated in 
registered reports venues \cite{chambers2019s} from qualitative researchers (who are getting their experimental protocols checked before they start their experiments).
That said, there is nothing in principle stopping artifact review committees from 
reviewing any of the following. For example, the IEEE Requirements Engineering Conference 2019 ran a artifacts track that reviewed items from both ends of this list.}\label{types}
{\scriptsize
\begin{tabular}{|p{.96\linewidth}|}\hline
\rowcolor{gray!15}\begin{enumerate}
\item
Motivational statements or reports or challenge statements or lists of open issues that prompt an analysis;
\item Hypotheses, about expected effects in some area;
\item Checklists used to design the analysis (see also   Checklist Manifesto http://atulgawande.com/book/the-checklist-manifesto/);
\item Bibliographies, comprehensive, annotated, and insightful (e.g. showing the development or open areas in a field);
\item Study instruments such as surveys interview scripts, etc;
\item Statistical tests used to analyze results (along with some notes explaining why or when this test is necessary);
\item Commentary on scripts used in the analysis;
\item Examples of particularly informative visualizations (e.g. see Sparklines
http://tiny.cc/sparklines)
\item Baseline results against which new work can be compared;
\end{enumerate}
\\\hline
\begin{enumerate}
 \setcounter{enumi}{11}
\item Sampling procedures e.g. ``how did you choose the projects you studied?'';
\item Patterns describing best practices for performing this kind of analysis;
\item Anti-patterns describing cautionary tales of ``gotchas'' to avoid when doing this kind of work;
\item Negative results that are anti-patterns, backed up by empirical results;
\item Tutorial materials: Guides to help newcomers become proficient in the area. Some of these tutorial materials may be generated by the researcher and others may be collected from other sources.
\item New results that offer guidance on how to best handle future problems.
\item Future work: From the results, there many be speculations about open issues of future issues that might become the motivation for the next round of research.
The actual text of an author's papers;
\end{enumerate}\\\hline

\rowcolor{green!5}\begin{enumerate}
 \setcounter{enumi}{18}
 
\item Any data used in an analysis
\begin{itemize}
\item
Either raw from a project;
\item
Or, if that is too large, some smaller derived product. Note that some data is too large to fit into the standard on-line freely available repos (e.g. Github only allows 1GB reps). For such data, we suggest using some other on-line storage; e.g. Zenodo accepts  50GB files and  higher quotas can be requested and granted on a case-by-case basis.
\end{itemize}
\item Scripts used to perform the analysis (the main analysis or the subsequent statistical tests or visualizations; e.g. the Python Sparklines generator). Scripts can also implement some of the patterns identified by the paper.
\item Executable models that can generate exemplar data; or which offer an executable form of current hypotheses;
\item Programs that realize the algorithms presented or used in the paper;
\item Delivery tools to let novices automatically rerun the analysis; e.g.
\begin{itemize}
\item
  Config management files that can
  \begin{itemize}
\item
build the system/ paper from raw material and/or
\item
update the relevant files using some package manager
\end{itemize}
\item
Virtual machines containing all the above scripts, data, etc, pre-configured such that a newcomer can automatically run the old analysis.
\end{itemize}
\end{enumerate}\\\hline
\end{tabular}}
\end{table}